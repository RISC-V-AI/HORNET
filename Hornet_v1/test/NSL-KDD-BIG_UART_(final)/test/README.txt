RISC-V Edge AI: Python Test Suite
=================================

## Overview

This directory contains the Python-based test suite for the RISC-V Edge AI project. The purpose of this suite is to perform automated hardware-in-the-loop (HIL) testing and verification & validation (V&V) of the neural network model.

The main script (`NSL-KDD_light_send.py`) works by:
1.  Reading floating-point input vectors from `inputs.txt`.
2.  Sending the raw bytes for each vector to the FPGA via a serial (UART) connection.
3.  Listening for the 1-byte inference result (the predicted class) sent back from the FPGA.
4.  Comparing the FPGA's prediction against the "ground truth" in `labels.txt`.
5.  Calculating and reporting the final accuracy.
6.  Saving the FPGA's raw predictions to `label_results.txt`.

---------------------------------

## File Descriptions

* `NSL-KDD_light_send.py`: The primary HIL test script. It sends all inputs to the FPGA, waits for a reply, and saves the result.
* `compare_all.py`: A V&V script that compares the ground-truth, C-model, and FPGA results and generates detailed metrics (F1-score, etc.).
* `inputs.txt`: The test dataset (e.g., 22,543 input vectors).
* `labels.txt`: The ground-truth (correct) labels corresponding to each vector in `inputs.txt`.
* `label_results.txt`: The output from the **local C-model** (the "golden" model).
* `FPGA_results.txt`: The output file generated by `NSL-KDD_light_send.py`, containing the raw predictions as returned by the FPGA.
* `.venv`: The virtual environment folder for Python and libraries. You may need to delete and re-install your own virtual environment.  

---------------------------------

## Requirements

* Python 3.x
* PySerial: `pip install pyserial`
* NumPy: `pip install numpy`
* Scikit-learn: `pip install scikit-learn` (for the V&V script)

---------------------------------

## Usage (HIL Test)

This is the primary method for testing your FPGA hardware. It runs the full test suite and saves the hardware's predictions.

Command:

(on windows)
python NSL-KDD_BIG_send.py --port COM3 --baud 115200 --inputs inputs.txt --labels labels.txt --bytes 488 --chunk 64 --delay 0.016 --output FPGA_results.txt

(on linux)
python3 NSL-KDD_BIG_send.py --port /dev/ttyUSB0   --baud 57600 --inputs inputs.txt --labels labels.txt --bytes 488 --chunk 64 --delay 0.001 --output FPGA_results.txt    

!!!NOTE: In Linux based OSs python --> python3 (or pip/pip3 in some cases). 
!!!NOTE: In Linux the baudrate is would be the half of what has implemented in Vivado. I believe thats because a divisin difference between Linux and Windows Vivado.  

Argument Explanation:
* `--port COM3`: The COM port your FPGA is connected to (e.g., `COM3`, `COM5`, or `/dev/ttyUSB0` on Linux).
* `--baud 115200`: The baud rate. **Must** match the setting in your FPGA's Verilog design.
* `--inputs inputs.txt`: The input data file.
* `--labels labels.txt`: The ground-truth answers.
* `--bytes 488`: The total number of bytes for a *single* input vector (122 floats * 4 bytes/float = 488 bytes).
* `--chunk 64` & `--delay 0.016`: **These are critical for stability.** This "software flow control" sends the data in 64-byte chunks and pauses for 16ms between them, which prevents overwhelming the RISC-V's interrupt handler and input buffer.
* `--output FPGA_results.txt`: Saves all predictions received from the FPGA to this new file.

This test lasted about 20 mins on Nexys Video FPGA. Tested with the original NSl-KDD test dataset with 22543 inputs.

---------------------------------

## Verification & Validation (V&V)

After running the HIL test (and your local C test to generate `label_results.txt`), you can run the `compare_all.py` script to get a detailed report of your system's performance.

This script compares the three label files and generates three separate reports, including accuracy, F1-score, and a confusion matrix for each. (REMEMBER: For this 
reports, you may need to install scikit-learn library: pip install scikit-learn)

Command:

python compare_all.py --truth labels.txt --c-local label_results.txt --fpga-uart FPGA_results.txt

### How to Read the Reports:

1.  **Report 1: Truth vs. C-Local (`label_results.txt`)**
    * This shows the "golden model" accuracy. It tells you how accurate your C-code implementation is against the true dataset.

2.  **Report 2: Truth vs. FPGA-UART (`FPGA_results.txt`)**
    * This shows the final, end-to-end accuracy of your entire hardware system.

3.  **Report 3: C-Local (`label_results.txt`) vs. FPGA-UART (`FPGA_results.txt`)**
    * This is the **consistency check**. A 100% accuracy here proves that your hardware is *perfectly* replicating your C-code simulation, with no data corruption or errors from the UART transfer.